<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

    <!-- Hive Configuration can either be stored in this file or in the hadoop configuration files  -->
    <!-- that are implied by Hadoop setup variables.                                                -->
    <!-- Aside from Hadoop setup variables - this file is provided as a convenience so that Hive    -->
    <!-- users do not have to edit hadoop configuration files (that may be managed as a centralized -->
    <!-- resource).                                                                                 -->

    <!-- Hive Execution Parameters -->
    <property>
        <name>hive.exec.mode.local.auto</name>
        <value>false</value>
        <description>Let hive determine whether to run in local mode automatically</description>
    </property>

    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>cfs:///user/spark/warehouse</value>
        <description>location of default database for the warehouse</description>
    </property>

    <property>
        <name>hive.metastore.rawstore.impl</name>
        <value>com.datastax.bdp.hadoop.hive.metastore.CassandraHiveMetaStore</value>
        <description>Use the Apache Cassandra Hive RawStore implementation</description>
    </property>

    <property>
        <name>hadoop.bin.path</name>
        <value>${dse.bin}/dse hadoop</value>
    </property>

    <!-- Set this to true to enable auto-creation of Cassandra keyspaces as Hive Databases -->
    <property>
        <name>cassandra.autoCreateHiveSchema</name>
        <value>true</value>
    </property>

    <property>
        <name>spark.enable</name>
        <value>true</value>
    </property>

    <property>
        <name>cassandra.connection.metaStoreColumnFamilyName</name>
        <value>sparkmetastore</value>
    </property>

    <property>
      <name>hive.server2.enable.doAs</name>
      <value>false</value>
    </property>

    <property>
      <name>hive.server2.logging.operation.enabled</name>
      <value>false</value>
    </property>

    <property>
      <name>cassandra.port</name>
      <value>${cassandra.connection.native.port}</value>
    </property>

    <!-- Spark SQL Thrift Server security configuration -->
    <!--
    <property>
      <name>hive.server2.authentication.kerberos.principal</name>
      <value>hiveserver2/_HOST@EXAMPLE.COM</value>
    </property>

    <property>
      <name>hive.server2.authentication.kerberos.keytab</name>
      <value>/path/to/hiveserver2.keytab</value>
    </property>

    <property>
      <name>hive.server2.authentication</name>
      <value>kerberos</value>
    </property>
    -->
</configuration>
